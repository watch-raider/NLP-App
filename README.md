# NLP PDF Data Extractor Pipeline

## Summary
This is a general purpose pipeline for extracting data from a PDF. The PDF can be of any type of document and the user can specify what fields they would like to extract. The output will be JSON with the extracted data fields.
The motivation of this research is that the Gemini LLM performs very well on this task but of course would incur cost when performing on a large scale. That is why I am interested in how smaller models that can be run locally,
such as Llama 1B and Llama 3B can perform on this task. If the performance if close enough to Gemini, it would allow users to perform data extraction capabilities without the need of a internet connection or the requirement of
expensive computing power.

## Table of Contents
- [Installation](#installation)
- [Usage](#usage)
- [Results](#results)

## Installation
1. Clone the repository:
```bash
git clone https://github.com/watch-raider/NLP-App.git
```

2. Install dependencies:
```bash
streamlit
langchain
langchain-google-genai
llmwhisperer-client
pydantic
python-dotenv
pandas
torch
torchvision
 ```

## Usage
To run the project, use the following command:
```bash
streamlit run research.py
```

### Startup
When you launch the project with streamlit, you will first need to insert all the necessary API keys. 
If you only plan on using the Gemini model then you can just enter the Google API key and LLM Whisperer API key fields but if you plan on using the Llama models you will need to download them locally from Hugging Face
and provide the directory path to the Llama 1B and 3B models. You will also need to provide your Hugging Face access token. 
1. First step is to upload the PDF you wish to extract data from
2. then specify what the document is e.g. Invoice, Resume etc...
3. Finally select the model you wish to use for your data extraction.  

![alt text](https://github.com/watch-raider/NLP-App/blob/main/screenshots/setup.png?raw=true)  

### Data Fields
Specify the data fields you wish to extract from the PDF and their datatype. Once you have added all the data fields, you can click the 'Generate prompts' and the selected LLM will generate prompts for the data fields.

![alt text](https://github.com/watch-raider/NLP-App/blob/main/screenshots/data_fields.png?raw=true)  

### Prompts
You can view the prompts generated by the LLM and edit them if required. Once you are happy with the prompts, you can then click the 'Confirm Prompts' button to start the data extraction process

![alt text](https://github.com/watch-raider/NLP-App/blob/main/screenshots/prompts.png?raw=true)  

### Output
Once the LLM has finished Processing, the output will show the JSON containing the extracted data fields.  

![alt text](https://github.com/watch-raider/NLP-App/blob/main/screenshots/output.png?raw=true)  

## Results
screenshots/setup.png  

As part of my research I compared the data extraction ability of the Llama 1B and 3B which can be run locally on CPU, against the output of the Google Gemini model using the Levenshtein distance metric.
If one of the Llama models have been selected to generate the output you can use the 'Measure' button to compare its' output against the Gemini model. I compared the results of the Llama 1B and 3B model against
the Gemini model across 10 invoices. Here are the preliminary results for each model:  

### Llama 1B Instruct
![alt text](https://github.com/watch-raider/NLP-App/blob/main/screenshots/history_llama_1B.png?raw=true)  

### Llama 3B Instruct
![alt text](https://github.com/watch-raider/NLP-App/blob/main/screenshots/history_llama_3B.png?raw=true)  

### Initial Conclusion
The Llama 3B model performs much better for this pipeline with an average accuracy of over 70% for all fields, compared to less than 50% accuracy for the 1B model for data extraction on Invoices. The results also give us 
indictation of which fields the Models perform well on. For example, the Llama models perform well when extraction simple fields such as Invoice number but poorly when asked to add up the quantities to return the total quantity
of items on the Invoice. These results are just preliminary and the models will need to be run on more data in order to obtain more conclusive results.
The next phase of the project would be to fine-tune the models for data extraction on Invoices and other document types to see how much the performance can be improved by.
